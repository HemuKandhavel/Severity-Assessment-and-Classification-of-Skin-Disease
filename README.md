# Severity-Assessment-and-Classification-of-Skin-Disease
A hybrid framework for **skin disease severity classification** using EfficientNet-B0 for lesion segmentation and feature extraction. Grad-CAM improves interpretability by highlighting critical regions, while a Random Forest classifier enables accurate and reliable severity assessment for clinical decision support.

** #Finding the Most Suitable Feature Extractor Using EfficientNet **
EfficientNetB0 was examined as the main feature extractor because of its well-structured design and proven effectiveness in medical imaging applications. In comparison to traditional CNNs like VGG-16 and ResNet50, EfficientNetB0 obtained a superior accuracy rate of 63% while requiring a smaller number of trainable parameters. The compound scaling strategy enabled the efficient extraction of both low-level and high-level lesion patterns. The model demonstrated excellent ability to distinguish between different dermoscopic images, showing its capacity to apply features from natural images to recognise medical skin patterns effectively. By freezing the initial convolutional layers and fine-tuning the subsequent ones, a reliable transfer learning procedure was established that helped avoid overfitting. This approach is particularly beneficial due to the common constraints associated with the small dataset sizes found in medical classification. The findings validate EfficientNetB0 as an appropriate foundation for tasks related to lesion recognition 

**#Finding the Region of Interest (ROI) via Image Segmentations- **
Correctly isolating the region of interest (ROI) is essential because dermoscopic images might include distractions like hair, rulers, shadows, or background pixels that can diminish the performance of classification. Image segmentation was utilized to identify the area of the lesion, commonly using methods like U-Net based segmentation or thresholding techniques. The divided region of interest retained only important clinical pixels and eliminated any noise and background. This enhanced the ratio of useful signals to unwanted noise in further processing. The visual assessment indicated that the segmentation results closely corresponded to the edges of the lesions. Furthermore, the classification outcomes were enhanced as the model concentrated solely on biologically important structures, disregarding adjacent skin or artifacts. 

**#Finding the Grad-CAM Visualization for All Nine Classes- **
Understanding how medical decision support systems work is crucial. Grad-CAM (Gradient- weighted Class Activation Mapping) was utilized to generate visual heatmaps for each of the nine lesion categories. For non-cancerous lesions, Grad-CAM indicated areas with smooth colors and even pigmentation, whereas cancerous cases demonstrated significant activation near irregular edges, asymmetry, and patches with multiple tones. These visual representations indicated that the model was not making random choices but instead concentrating on areas that are important for diagnosis. This enhances clinical confidence and enables dermatologists to verify the model's reasoning. 

**#Finding the Output of Skin Lesion Attribute Extraction)- **
Dermoscopy features—like pigment networks, streaks, globules, dots, and blue-white structures—were examined during the process of feature extraction. The model effectively identified connections between certain visual traits and specific types of lesions. For instance, the occurrence of uneven streaks and varied coloration was closely related to melanoma, whereas uniform textures were often associated with harmless nevi. The obtained attributes improved the understanding and dependability of the final predictions.. 

**#Finding the Suitable Classifier Selection **
Several classifiers, including the fully connected softmax classifier integrated within EfficientNet and an external XGBoost model, were evaluated using the extracted features. The softmax-based classifier provided the strongest performance, achieving an accuracy of 95%. This superiority is largely due to the end-to-end optimization, where the classifier and feature extractor are trained jointly, allowing the network to progressively refine features that best separate the nine lesion categories. As a result, the model learned class boundaries more effectively, showed faster and more stable convergence during training, and demonstrated stronger generalization when evaluated on unseen test images. In comparison, external classifiers such as XGBoost relied on static feature vectors and therefore lacked this integrated adaptation. The combined representation learning and optimization within EfficientNet led to improved robustness and predictive reliability, making the softmax-based efficient classifier the most suitable choice for automated skin lesion diagnosis in this study 
7.6 Single-Image Output Prediction 
A user-provided image is passed through the complete processing pipeline, including ROI segmentation, feature extraction, classification, and Grad-CAM visualization. In the evaluated test case, a dermoscopic image of a nevus was processed and correctly classified with 89.54% confidence. The system also generated an accompanying Grad-CAM heatmap highlighting the lesion regions that mainly influenced the model’s decision, ensuring the prediction is not only accurate but also transparent and clinically interpretable. 
<img width="468" height="647" alt="image" src="https://github.com/user-attachments/assets/6cdc3a93-3663-4ea1-a4df-d2e38aee0226" />
